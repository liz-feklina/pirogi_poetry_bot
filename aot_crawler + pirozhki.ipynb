{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть первая - обкачка aot ( http://aot.ru/demo/morph.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_dict = dd(set)\n",
    "word_dict = dd(set)\n",
    "nom_accent_dict = dd(set)\n",
    "nom_word_dict = dd(set)\n",
    "ins_accent_dict = dd(set)\n",
    "ins_word_dict = dd(set)\n",
    "dat_accent_dict = dd(set)\n",
    "dat_word_dict = dd(set)\n",
    "acc_accent_dict = dd(set)\n",
    "acc_word_dict = dd(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, делающая запрос сайту и возвращающая json со всеми вариантами слова и их парадигмами (с проставленным ударением, если слово найдено в словаре)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aot_json(word):\n",
    "    url = 'http://63.250.59.227:8080/?'\n",
    "    data = {'action': 'morph',\n",
    "            'langua': 'Russian',\n",
    "            'query': word,\n",
    "            'withparadigms': '1',}\n",
    "    html_content = requests.get(url, data).text\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"commonGrammems\":\"но\",\"found\":true,\"morphInfo\":\"С жр,им,ед\",\"paradigm\":[{\"formsGroups\":[{\"forms\":[{\"f\":\"КУ'КЛА\",\"grm\":\"им\"},{\"f\":\"КУ'КЛЫ\",\"grm\":\"рд\"},{\"f\":\"КУ'КЛЕ\",\"grm\":\"дт\"},{\"f\":\"КУ'КЛУ\",\"grm\":\"вн\"},{\"f\":\"КУ'КЛОЮ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛОЙ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛЕ\",\"grm\":\"пр\"}],\"grm\":\"ед\"},{\"forms\":[{\"f\":\"КУ'КЛЫ\",\"grm\":\"им\"},{\"f\":\"КУ'КОЛ\",\"grm\":\"рд\"},{\"f\":\"КУ'КЛАМ\",\"grm\":\"дт\"},{\"f\":\"КУ'КЛЫ\",\"grm\":\"вн\"},{\"f\":\"КУ'КЛАМИ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛАХ\",\"grm\":\"пр\"}],\"grm\":\"мн\"}],\"pos\":\"СУЩЕСТВИТЕЛЬНОЕ жр\"}],\"wordForm\":\"КУКЛА\"},{\"commonGrammems\":\"од\",\"found\":true,\"morphInfo\":\"С жр,им,ед\",\"paradigm\":[{\"formsGroups\":[{\"forms\":[{\"f\":\"КУ'КЛА\",\"grm\":\"им\"},{\"f\":\"КУ'КЛЫ\",\"grm\":\"рд\"},{\"f\":\"КУ'КЛЕ\",\"grm\":\"дт\"},{\"f\":\"КУ'КЛУ\",\"grm\":\"вн\"},{\"f\":\"КУ'КЛОЮ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛОЙ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛЕ\",\"grm\":\"пр\"}],\"grm\":\"ед\"},{\"forms\":[{\"f\":\"КУ'КЛЫ\",\"grm\":\"им\"},{\"f\":\"КУ'КОЛ\",\"grm\":\"рд\"},{\"f\":\"КУ'КЛАМ\",\"grm\":\"дт\"},{\"f\":\"КУ'КОЛ\",\"grm\":\"вн\"},{\"f\":\"КУ'КЛАМИ\",\"grm\":\"тв\"},{\"f\":\"КУ'КЛАХ\",\"grm\":\"пр\"}],\"grm\":\"мн\"}],\"pos\":\"СУЩЕСТВИТЕЛЬНОЕ жр\"}],\"wordForm\":\"КУКЛА\"}]\n"
     ]
    }
   ],
   "source": [
    "print(get_aot_json('кукла'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, достающая список слов, при необходимости только конкретного(ых) падежа(ей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordlist(word, cases='им,рд,дт,вн,тв,пр'):\n",
    "    a = get_aot_json(word)\n",
    "    b = json.loads(a)\n",
    "    forms_list = []\n",
    "    cases = cases.split(',')\n",
    "    for paradigm in b[0]['paradigm']:\n",
    "        for formsGroup in paradigm['formsGroups']:\n",
    "            for form in formsGroup['forms']:\n",
    "                if form['grm'] in cases:\n",
    "                    forms_list.append(form['f'])\n",
    "    return forms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ШНУРО'К\", \"ШНУРКА'\", \"ШНУРКУ'\", \"ШНУРО'К\", \"ШНУРКО'М\", \"ШНУРКЕ'\", \"ШНУРКИ'\", \"ШНУРКО'В\", \"ШНУРКА'М\", \"ШНУРКИ'\", \"ШНУРКА'МИ\", \"ШНУРКА'Х\"]\n",
      "[\"ШНУРО'К\", \"ШНУРКУ'\", \"ШНУРКИ'\", \"ШНУРКА'М\"]\n"
     ]
    }
   ],
   "source": [
    "print(get_wordlist('шнурок'))\n",
    "print(get_wordlist('шнурок', cases='дт,им'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"УЖИ'Н\", \"У'ЖИН\", \"УЖИ'НА\", \"У'ЖИНА\", \"УЖИ'НУ\", \"У'ЖИНУ\", \"УЖИ'Н\", \"У'ЖИН\", \"УЖИ'НОМ\", \"У'ЖИНОМ\", \"УЖИ'НЕ\", \"У'ЖИНЕ\", \"У'ЖИНЫ\", \"УЖИ'НЫ\", \"УЖИ'НОВ\", \"У'ЖИНОВ\", \"УЖИ'НАМ\", \"У'ЖИНАМ\", \"УЖИ'НЫ\", \"У'ЖИНЫ\", \"УЖИ'НАМИ\", \"У'ЖИНАМИ\", \"УЖИ'НАХ\", \"У'ЖИНАХ\"]\n",
      "[\"ШНУРО'К\", \"ШНУРКУ'\", \"ШНУРКИ'\", \"ШНУРКА'М\"]\n"
     ]
    }
   ],
   "source": [
    "print(get_wordlist('ужин'))\n",
    "print(get_wordlist('шнурок', cases='дт,им'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, добавляющая словоформы в словари:\n",
    "- в accent_dict ключи - кортежи из количества слогов и номера ударного слога, значения - слова (уже без знака ударения)\n",
    "- в word_dict наоборот, ключи - слова, значения - кортежи из количества слогов и номера ударного слога\n",
    "\n",
    "количество слогов считается по количеству гласных, ударный слог определяется количеством гласных перед апострофом (обозначением ударения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_accents(wordlist, dict_accents, dict_words):\n",
    "    vowels = ['А', 'Е', 'И', 'О', 'У', 'Ы', 'Э', 'Ю', 'Я']\n",
    "    for word in wordlist:\n",
    "        parts = word.split(\"'\")\n",
    "        if len(parts) == 2:\n",
    "            vown = 0\n",
    "            for ch in parts[0]:\n",
    "                if ch in vowels:\n",
    "                    vown += 1\n",
    "            accent_num = copy.deepcopy(vown)\n",
    "            for ch in parts[1]:\n",
    "                if ch in vowels:\n",
    "                    vown += 1\n",
    "            syllable_num = copy.deepcopy(vown)\n",
    "            new_word = ''.join(parts)\n",
    "            key_tuple = (syllable_num, accent_num)\n",
    "            dict_accents[key_tuple].add(new_word)\n",
    "            dict_words[new_word].add(key_tuple)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как это выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_accents(get_wordlist('корова'), accent_dict, word_dict)\n",
    "def_accents(get_wordlist('коза'), accent_dict, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {(3, 2): {'КОЗОЮ',\n",
       "              'КОРОВА',\n",
       "              'КОРОВАМ',\n",
       "              'КОРОВАХ',\n",
       "              'КОРОВЕ',\n",
       "              'КОРОВОЙ',\n",
       "              'КОРОВУ',\n",
       "              'КОРОВЫ'},\n",
       "             (4, 2): {'КОРОВАМИ', 'КОРОВОЮ'},\n",
       "             (2, 2): {'КОЗА', 'КОЗЕ', 'КОЗОЙ', 'КОЗУ', 'КОЗЫ', 'КОРОВ'},\n",
       "             (2, 1): {'КОЗАМ', 'КОЗАХ', 'КОЗЫ'},\n",
       "             (1, 1): {'КОЗ'},\n",
       "             (3, 1): {'КОЗАМИ'}})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'КОРОВА': {(3, 2)},\n",
       "             'КОРОВЫ': {(3, 2)},\n",
       "             'КОРОВЕ': {(3, 2)},\n",
       "             'КОРОВУ': {(3, 2)},\n",
       "             'КОРОВОЮ': {(4, 2)},\n",
       "             'КОРОВОЙ': {(3, 2)},\n",
       "             'КОРОВ': {(2, 2)},\n",
       "             'КОРОВАМ': {(3, 2)},\n",
       "             'КОРОВАМИ': {(4, 2)},\n",
       "             'КОРОВАХ': {(3, 2)},\n",
       "             'КОЗА': {(2, 2)},\n",
       "             'КОЗЫ': {(2, 1), (2, 2)},\n",
       "             'КОЗЕ': {(2, 2)},\n",
       "             'КОЗУ': {(2, 2)},\n",
       "             'КОЗОЮ': {(3, 2)},\n",
       "             'КОЗОЙ': {(2, 2)},\n",
       "             'КОЗ': {(1, 1)},\n",
       "             'КОЗАМ': {(2, 1)},\n",
       "             'КОЗАМИ': {(3, 1)},\n",
       "             'КОЗАХ': {(2, 1)}})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём наш список слов и преобразуем с помощью этих функций в словарь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " вод­ка, во­ен­ный, вождь, воз­вра­ще­ние, воз­дух, воз­мож­ность, воз­раст, во­ин, вой, вой­на, вок\n"
     ]
    }
   ],
   "source": [
    "with open('codenames_biggest_one.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    print(text[2200:2300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слов 2272\n"
     ]
    }
   ],
   "source": [
    "words = text\n",
    "words = words.replace('­','').split(', ')\n",
    "print('слов', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:05<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(words[-10:]):\n",
    "    def_accents(get_wordlist(word), accent_dict, word_dict)\n",
    "    def_accents(get_wordlist(word, 'им'), nom_accent_dict, nom_word_dict)\n",
    "    def_accents(get_wordlist(word, 'тв'), ins_accent_dict, ins_word_dict)\n",
    "    def_accents(get_wordlist(word, 'дт'), dat_accent_dict, dat_word_dict)\n",
    "    def_accents(get_wordlist(word, 'вн'), acc_accent_dict, acc_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('codenames_big_dicts.pickle', 'wb') as handle:\n",
    "    pickle.dump([accent_dict, word_dict, nom_accent_dict, nom_word_dict, ins_accent_dict, ins_word_dict, dat_accent_dict, dat_word_dict, acc_accent_dict, acc_word_dict], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('codenames_big_dicts.pickle', 'rb') as handle:\n",
    "    dict_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_dict, word_dict, nom_accent_dict, nom_word_dict, ins_accent_dict, ins_word_dict, dat_accent_dict, dat_word_dict, acc_accent_dict, acc_word_dict = dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть вторая - генерация стихотворения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, создающая строку, написанную двухсложным метром с ударением на всех чётных или нечётных слогах:\n",
    "- подбираются все возможные комбинации количества слогов и номера ударного слога для данного момента строки\n",
    "- слова из них объединяются в один список\n",
    "- выбирается случайное\n",
    "- слово добавляется в строку, количество слогов вычитается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poetry(n, ac, dict_accents, dict_words):\n",
    "    stroka = []\n",
    "    str_len = ac #(уже заполнено)\n",
    "    full = n+ac #(длина итоговой строки)\n",
    "    \n",
    "    while True:\n",
    "        if full - str_len == 3:\n",
    "            word = random.choice(list(dict_accents[(3,str_len%2 + 2)]))\n",
    "            stroka.append(word.lower())\n",
    "            str_len += 3\n",
    "            break\n",
    "        if full - str_len == 1:\n",
    "            word = random.choice(list(dict_accents[(1, 1)]))\n",
    "            stroka.append(word.lower())\n",
    "            str_len += 1\n",
    "            break\n",
    "        else:\n",
    "            #keys = (любое число от 1 до 4, набор ударений: или [1,3] или [2,4]str_len%2)\n",
    "            keys = []\n",
    "            if str_len%2 == 0:\n",
    "                accents = [2, 4]\n",
    "            else:\n",
    "                accents = [1, 3]\n",
    "            for i in range(1,min(4, full-str_len+1)):\n",
    "                if (full-str_len-i) != 1:\n",
    "                    for j in accents:\n",
    "                        if not (full-str_len == 4 and i == 4 and j in [1,2]):\n",
    "                            keys.append((i,j))\n",
    "            w_list = []\n",
    "            for key in keys:\n",
    "                w_list.extend(list(dict_accents[key]))\n",
    "            word = random.choice(w_list)\n",
    "            stroka.append(word.lower())\n",
    "            str_len += list(dict_words[word])[0][0]\n",
    "            if full-str_len == 1:\n",
    "                print(stroka)\n",
    "        if str_len == full:\n",
    "            break\n",
    "    return ' '.join(stroka)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация, полностью из случайных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def random_poem(dict1, dict2):\n",
    "    poem = '\\n'.join([poetry(9, 2, dict1, dict2),\n",
    "                       poetry(8, 2, dict1, dict2),\n",
    "                       poetry(9, 2, dict1, dict2),\n",
    "                       poetry(8, 2, dict1, dict2)])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "смертях скандал беседам штампы\n",
      "зрачки война весны пятков\n",
      "резервы личности обходом\n",
      "вилков натур клокам сетям\n"
     ]
    }
   ],
   "source": [
    "print(random_poem(accent_dict, word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "платок беседы нерв аккорды\n",
      "цветы просмотры миллион\n",
      "телега перья мальчик штуки\n",
      "супруги жулик красота\n"
     ]
    }
   ],
   "source": [
    "print(random_poem(nom_accent_dict, nom_word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация со вспомогательными строками и закрепленным падежом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def template1(nom_dict1, nom_dict2):\n",
    "    poem = '\\n'.join(['заходит в дом олег под вечер',\n",
    "                      'а там ' + poetry(6, 2, nom_dict1, nom_dict2),\n",
    "                      poetry(9, 2, nom_dict1, nom_dict2),\n",
    "                      'и дом вообще-то не его'])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "заходит в дом олег под вечер\n",
      "а там печать сады сеанс\n",
      "мечта вокзалы гром презренья\n",
      "и дом вообще-то не его\n"
     ]
    }
   ],
   "source": [
    "print(template1(nom_accent_dict, nom_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template2(ins_dict1, ins_dict2):\n",
    "    poem = '\\n'.join(['оксана мчится ' + poetry(4, 1, ins_dict1, ins_dict2),\n",
    "                      poetry(8, 2, ins_dict1, ins_dict2),\n",
    "                      poetry(9, 2, ins_dict1, ins_dict2),\n",
    "                      'но магазин уже закрыт'])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "оксана мчится детством бомбой\n",
      "цепочкой взрослою тайгой\n",
      "уроком болями бутылкой\n",
      "но магазин уже закрыт\n"
     ]
    }
   ],
   "source": [
    "print(template2(ins_accent_dict, ins_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template3(nom_dict1, nom_dict2):\n",
    "    poem = '\\n'.join(['у роботов другие чувства',\n",
    "                      'не ' + poetry(1, 1, nom_dict1, nom_dict2)\n",
    "                      + ' не ' + poetry(2, 1, nom_dict1, nom_dict2)\n",
    "                      + ' не ' + poetry(2, 2, nom_dict1, nom_dict2),\n",
    "                      'а ' + poetry(8, 1, nom_dict1, nom_dict2),\n",
    "                      poetry(5, 2, nom_dict1, nom_dict2) + ' и ' + poetry(2, 2, nom_dict1, nom_dict2)])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "у роботов другие чувства\n",
      "не плоть не принцип не перрон\n",
      "а опыты йогурт советы\n",
      "икона буква и прием\n"
     ]
    }
   ],
   "source": [
    "print(template3(nom_accent_dict, nom_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template4(dat_dict1, acc_dict1):\n",
    "    poem = '\\n'.join([random.choice(list(dat_dict1[(3, 2)])).lower() + ' ' +\n",
    "                      random.choice(list(acc_dict1[(3, 1)])).lower() + ' и ' +\n",
    "                      random.choice(list(acc_dict1[(2, 1)])).lower(),\n",
    "                      random.choice(list(dat_dict1[(2, 2)])).lower() + ' ' +\n",
    "                      random.choice(list(acc_dict1[(4, 2)])).lower() + ' и ' +\n",
    "                      random.choice(list(acc_dict1[(1, 1)])).lower(),\n",
    "                      random.choice(list(dat_dict1[(3, 2)])).lower() + ' ' +\n",
    "                      random.choice(list(acc_dict1[(1, 1)])).lower() + ' и ' +\n",
    "                      random.choice(list(acc_dict1[(4, 3)])).lower(),\n",
    "                      'а мне ' + random.choice(list(acc_dict1[(3, 2)])).lower() +\n",
    "                      ' и ' + random.choice(list(acc_dict1[(2, 2)])).lower()])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "условьям отдыхи и ласок\n",
      "плащу шампанское и рельс\n",
      "усмешкам суп и сообщенья\n",
      "а мне ступени и вопрос\n"
     ]
    }
   ],
   "source": [
    "print(template4(dat_accent_dict, acc_accent_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть третья - начинаем генерировать сос мыслом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем готовую семантическую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
       " <http.client.HTTPMessage at 0x6271610>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, создающая по слову отдельный словарь из близких ему слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_dict(word):\n",
    "    \n",
    "    custom_accent_dict = dd(set)\n",
    "    custom_word_dict = dd(set)\n",
    "    custom_nom_accent_dict = dd(set)\n",
    "    custom_nom_word_dict = dd(set)\n",
    "    custom_ins_accent_dict = dd(set)\n",
    "    custom_ins_word_dict = dd(set)\n",
    "    custom_dat_accent_dict = dd(set)\n",
    "    custom_dat_word_dict = dd(set)\n",
    "    custom_acc_accent_dict = dd(set)\n",
    "    custom_acc_word_dict = dd(set)\n",
    "    \n",
    "    try:\n",
    "        a = model.most_similar(positive=[word], topn=200)\n",
    "    except Exception:\n",
    "        print('Слово не найдено(')\n",
    "        return 'error'\n",
    "    close_words = [word.split('_')[0] for (word, num) in a]\n",
    "    for w in tqdm(close_words):\n",
    "        def_accents(get_wordlist(w), custom_accent_dict, custom_word_dict)\n",
    "        def_accents(get_wordlist(w, 'им'), custom_nom_accent_dict, custom_nom_word_dict)\n",
    "        def_accents(get_wordlist(w, 'тв'), custom_ins_accent_dict, custom_ins_word_dict)\n",
    "        def_accents(get_wordlist(w, 'дт'), custom_dat_accent_dict, custom_dat_word_dict)\n",
    "        def_accents(get_wordlist(w, 'вн'), custom_acc_accent_dict, custom_acc_word_dict)\n",
    "    return [custom_accent_dict, custom_word_dict, custom_nom_accent_dict, custom_nom_word_dict, custom_ins_accent_dict, custom_ins_word_dict, custom_dat_accent_dict, custom_dat_word_dict, custom_acc_accent_dict, custom_acc_word_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим несколько наборов на разные темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:08<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "music_dicts = create_custom_dict('музыка_S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:21<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "zoo_dicts = create_custom_dict('животное_S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:08<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "wind_dicts = create_custom_dict('ветер_S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:11<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:12<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "robot_dicts = create_custom_dict('робот_S')\n",
    "love_dicts = create_custom_dict('любовь_S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:07<00:00,  1.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [02:08<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "human_dicts = create_custom_dict('человек_S')\n",
    "gift_dicts = create_custom_dict('подарок_S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прелюдам вальса арф фанфарам\n",
      "сюитам арфою певцам\n",
      "зурнах матчишах вальсу ритму\n",
      "дуэтов фуге гопаком\n"
     ]
    }
   ],
   "source": [
    "print(random_poem(music_dicts[0], music_dicts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "заходит в дом олег под вечер\n",
      "а там скотина грызуны\n",
      "подсвинок пес горилла кошка\n",
      "и дом вообще-то не его\n"
     ]
    }
   ],
   "source": [
    "print(template1(zoo_dicts[2], zoo_dicts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "оксана мчится штормом мозглым\n",
      "крылами бурею крылом\n",
      "струенным моросью метелью\n",
      "но магазин уже закрыт\n"
     ]
    }
   ],
   "source": [
    "print(template2(wind_dicts[4], wind_dicts[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немножко изменим существующий шаблон, чтобы можно было указать два разных набора словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template3_1(nom_dict1, nom_dict2, nom_dict3, nom_dict4):\n",
    "    poem = '\\n'.join(['у роботов другие чувства',\n",
    "                      'не ' + poetry(1, 1, nom_dict1, nom_dict2)\n",
    "                      + ' не ' + poetry(2, 1, nom_dict1, nom_dict2)\n",
    "                      + ' не ' + poetry(2, 2, nom_dict1, nom_dict2),\n",
    "                      'а ' + poetry(8, 1, nom_dict3, nom_dict4),\n",
    "                      poetry(5, 2, nom_dict3, nom_dict4) + ' и ' + poetry(2, 2, nom_dict3, nom_dict4)])\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "у роботов другие чувства\n",
      "не скорбь не дружбы не мечта\n",
      "а пульты рация селектор\n",
      "локатор мазер и модель\n"
     ]
    }
   ],
   "source": [
    "print(template3_1(love_dicts[2], love_dicts[3], robot_dicts[2], robot_dicts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "счастливцам весточку и снимку\n",
      "вещам приветствие и брошь\n",
      "туземцам дар и побрякушки\n",
      "а мне наследство и калым\n"
     ]
    }
   ],
   "source": [
    "print(template4(human_dicts[6], gift_dicts[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "людишкам складчины и торты\n",
      "парням дарящее и торт\n",
      "народам дар и шоколадку\n",
      "а мне гостинец и бювар\n"
     ]
    }
   ],
   "source": [
    "print(template4(human_dicts[6], gift_dicts[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
